{
"home": {
	"title": "ARTICT | Art Through the ICT Lens: Big Data Processing Tools to Support the Technical Study, Preservation and Conservation of Old Master Paintings​",
	"content": "<h3>EPSRC-funded research partnership between University College London, Imperial College London and the National Gallery</h3><br/><p>The heritage science sector is experiencing a digital revolution linked to the emergence and increasing adoption of cutting-edge non-invasive analytical imaging techniques generating large volumes of multidimensional data from cultural heritage objects. These include macro X-Ray fluorescence (MA-XRF) scanning and hyperspectral imaging (HSI). Combining MA-XRF and HSI data - providing elemental and molecular information - offers huge potential for improved identification, characterization, and visualisation of the materials and features of interest in a painting, including in sub-surface layers of the painting. However, it is increasingly recognised that the wealth of data associated with these modalities cannot be fully exploited through traditional primarily manual approaches to interrogating heritage science data.</p><p>The aim of this research - bringing together ICT and Heritage Science researchers to enable the cross-pollination of ideas and expertise - is to co-create new automatic signal analysis and processing tools that are able to <i>fuse</i> MA-XRF and HSI data to support the technical study, conservation and preservation artwork.</p><p>For more information about the project see the <a href=\"https://gtr.ukri.org/projects?ref=EP%2FR032785%2F1\">UKRI</a> and <a href=\"https://gow.epsrc.ukri.org/NGBOViewGrant.aspx?GrantRef=EP/R032785/1\">EPSRC</a> webpages about the project.</p>",
	"content right": "<img style=\"position:relative;width:100%;\" src=\"graphics/ARTICT_Goya.png\"/>"
	},
"team": {
    "class": "list",
    "file": "team.json",
	"title": "ARTICT - Team",
	"content": "[##]<h2>Contacts</h2><p>Please feel free to contact any of the investigators listed above or members of their teams. For more information about the <i>Computational approaches for technical imaging in cultural heritage (7th IP4AI meeting) conference</i>, please click <a href=\"https://research.ng-london.org.uk/external/ARTICT/events.html\">here</a></p><p>For all enquires about this conference, please use the conference email address: <a href=\"mailto:artict@ng-london.org.uk?Subject=ARTICT%20conference\" target=\"_top\">artict@ng-london.org.uk</a></p>",
	"content right": ""		
	},
"case studies": {
      "title": "ARTICT | Art Through the ICT Lens: Big Data Processing Tools to Support the Technical Study, Preservation and Conservation of Old Master Paintings",
	"content": "<div class=\"alert alert-info\" role=\"alert\">\r\n\t<h4 class=\"alert-heading\">Case Studies</h4>\r\n\t<p>These case studies, listed in the menu above, have been provided to illustrate the work being investigated in ARTICT, for more information please contact the appropriate members of the project <a href=\"./team.html\">Team</a>.</p>\r\n</div><p>The cultural heritage sector is experiencing a digital revolution driven by the growing adoption of non-invasive, non-destructive imaging and analytical approaches generating multi-dimensional data from entire artworks (e.g., hyperspectral imaging, macro X-ray fluorescence scanning, and novel forms of imaging X-ray radiography). </p>",
	"content right": ""},	
"case study one": {  
	"parent": "case studies",
	"title": "ARTICT - Pigment Identification using Machine Learning ",
	"content": "<center><figure class=\"figure\"><img src=\"https://wallacelive.wallacecollection.org/eMP/eMuseumPlus?service=DynamicAsset&sp=SU5mxm4Yx%2FVbhp94nksEmWhUPPCPARCxmRF3wZoiekBYI9dLioBnZzXySIRTomizoxxT9oo9OlonT%0APnyO6EhNhnOgOpQYyGgGmp9f4Yzsn%2FRogeai2vDoqajj1y2wZGfIxIqE9mglfu4%3D&sp=Simage%2Fjpeg\" class=\"figure-img img-fluid rounded\" style=\"max-width:384px;\" alt=\"Perseus and Andromeda\"><figcaption class=\"figure-caption\">Figure 1:<a href=\"https://wallacelive.wallacecollection.org:443/eMP/eMuseumPlus?service=ExternalInterface&module=collection&objectId=64901&viewType=detailView\"><h2>Challenge</h2><p>As a painting ages, parts of its pigment layers fall off or lose their original colors, due to chemical interactions with the surrounding environment. To maintain the completeness and vividness of the paintings, art conservators and restorers fill in areas of paint loss or repaint discolored areas. Identifying the pigments used in the creation of the artwork as well as differentiating between retouched and original areas of a painting are crucial in preserving it, reviving it and understanding its history. In recent decades non-invasive material detection techniques (e.g. X-ray fluorescence, abbreviated as XRF) have gained momentum throughout the cultural heritage scientific community. In the context of art conservation, these techniques allow for the detection of elements present in paintings under study; more precisely, algorithms designed for material detection (e.g., see  [link to Pierluigi’s case study]) process the XRF “data cube” and provide elemental maps (see Fig. 2 below) indicating the presence of various elements across the painting. However, even with the help of elemental maps, it is still a challenging task to identify pigments (typically compounds or mixtures of compounds that consist of several elements) and thereby distinguish retouched areas, based on the scrutiny of elemental maps one by one.</p><center><figure class=\"figure\"><img src=\"graphics/duke_fig2.jpg\" class=\"figure-img img-fluid rounded\" style=\"\" alt=\"example lead and titanium maps\"><figcaption class=\"figure-caption\">Figure 2: The elemental map of lead (left) shows where lead is present (brighter areas) in a section from Andromeda’s body in Perseus and Andromeda. Black dots throughout the map show where lead-containing paints were lost. The elemental map of titanium (right) shows refilled areas. Titanium compounds were not used as  pigments in Titian’s time (the element was discovered only in the 18th century); this anachronism confirms the brighter areas in the titanium map to be retouches, as already suspected by the matches between their shapes and those of paint losses in the lead map.<\/figcaption><\/figure><h2>Approach</h2><p>In this project, we use a wavelets-based representation to take advantage of the similarity between the maps for different elements in the spatial domain (joint sparsity in the wavelet representation) to provide pigment-mixture maps. These maps can be used by the investigators to both “read” the pigments (each of which is typically already a compound of several elements) used by the artist to create the painting, and identify retouches or fills in an automatic fashion (see Fig. 3 below). </p><\/center><center><figure class=\"figure\"><img src=\"graphics/duke_fig3.jpg\" class=\"figure-img img-fluid rounded\" style=\"\" alt=\"Example processed elemental maps\"><figcaption class=\"figure-caption\">Figure 3: The pigment-mixture map on the left is one of 9 maps that our model generated based on 13 elemental maps (calcium, chromium, cobalt, copper, iron, two lead maps, manganese, mercury, potassium, tin, titanium, zinc). This pigment has a high content of cobalt, often used for blue pigments; this is consistent with the pigment map largely corresponding to the blue background in the painting. The pigment-mixture map on the right, generated with the same model, largely matches with areas where titanium was detected. <\/figcaption><\/figure><\/center><div class=\"alert alert-success\" role=\"alert\">\r\n\t<b>Research Team: </b> <i>Duke University</i> - Ingrid Daubechies, Barak Sober, Hojung (Ashley) Kwon</div>",

	"content right": ""
	},
"case study two": {  
	"parent": "case studies",
	"title": "ARTICT - Algorithms that Helped Reveal Leonardo's Hidden Drawings",
	"content": "<h2>Challenge</h2><p>Macro X-Ray Fluorescence (XRF) scanning is an increasingly widely used imaging technique for the non-invasive detection and mapping of chemical elements in Old Master paintings. A macro XRF scanning device sequentially illuminates sub-millimetre spots (or pixels) of a painting with a primary X-ray beam that can penetrate through surface layers, exciting the emission of X-ray photons with energies that are specific to the chemical elements present within the pigments used in the painting. The X-ray photons emitted at each pixel are detected as a spectrum consisting of a collection of pulses due to all of the elements in this region. Hence, the presence of an element can be confirmed in a particular region if all the expected pulses corresponding to that element are detected within the XRF spectrum. However, paintings are created by complex pigment mixtures and therefore many elements are present at each single pixel often also due to the presence of  concealed designs below the surface. As a consequence of that it is quite common that pulses related to elements of interest in a painting overlap. The process to disentangle these pulses is very challenging and is known in the heritage sector as “deconvolution”.<h2>Approach</h2><p>Existing approaches for XRF signal deconvolution require varying degrees of expert user input. Our team  has developed a new fully automatic method to process XRF spectra. It automatically detects the pulses within the signal and produces the element distribution maps for the painting and a confidence map. The methods is able to separate nearby pulses and is also able to retrieve weak signals buried in noise [1]. Our approach leverages ideas in spectral estimation and sparse sampling theory to fully exploit the specific properties of the XRF spectra. The algorithm has helped the discovery of abandoned under-drawings in Leonardo’s “The Virgin of the Rocks” [1] (see also Fig.1).</p><center><figure class=\"figure\"><img src=\"graphics/imp_F1.jpg\" class=\"figure-img img-fluid rounded\" style=\"\" alt=\"Example processed elemental maps\"><figcaption class=\"figure-caption\">Figure 1. Fig.1(a): Zinc map revealing abandoned sketches of an angel beneath the “Virgin of the Rocks”. Fig1(b): Highlighted is the region of the “Virgin of the Rocks” where the XRF dataset was collected and where the hidden sketches shown were found. <\/figcaption><\/figure><\/center><h3>Representative Publications</h3><p>[1] S. Yan, J. Huang, N. Daly, C. Higgitt and P. L. Dragotti, “Revealing Hidden Drawings in Leonardo’s ‘the Virgin of the Rocks’ from Macro X-Ray Fluorescence Scanning Data through Element Line Localisation”, IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), May 2020.</p><h3>Representative Media Coverage</h3><p><a href=\"https://www.imperial.ac.uk/news/195075/new-algorithm-helps-uncover-forgotten-figures/\">“New algorithm helps uncover forgotten figures beneath da Vinci painting”</a>, Imperial Press (also reported by e.g., Daily Mail, CNN), February 2020.</p><div class=\"alert alert-success\" role=\"alert\">\r\n\t<b>Research Team: </b> <i>Imperial College London</i> - Yan Su, Junjie Huang, Maria Villafane, Pier Luigi Dragotti, <i>National Gallery, London</i> - Nathan Daly, Catherine Higgitt.</div>",
	"content right": ""
	},
"case study three": {  
	"parent": "case studies",
	"title": "ARTICT - Image Separation for Art Investigation",
	"content": "<h2>Challenge</h2><p>X-radiographs (X-ray images) are a particularly valuable tool during the examination and restoration of paintings because these can help establish the condition of a painting (e.g., whether there are losses and damages that may not be apparent at the surface, perhaps because of obscuring varnish, overpainted layers, structural issues, or cracks in the paint) and the status of different paint passages (e.g., help to identify retouchings or fills).</p><p>However, interpreting X-ray images can be problematic because – due to the penetration ability of x-rays – these can contain features appearing on the front, back, or even within the painting.</p><p>A classic example relates to the well-known polyptych panel painting The Adoration of the Mystic Lamb (the Ghent Altarpiece), completed before 1432 by the brothers Hubert and Jan van Eyck (see Figs. 1 and 2), where X-ray images of outer wing panels contain features of the paintings appearing both on the front and back of the panel (see Fig. 3).</p><p><i>The challenge relates to the separation of the mixed X-ray images from the double-sided panels into separate X-ray images of corresponding (imagined) “one-sided” paintings. </i></p><h2>Approach</h2><p>Our team has developed a suite of entirely new self-supervised deep learning based approaches to tackle this X-ray image separation problem [1,2]. Our approach leverages readily available visible (RGB) images of the paintings on each side of the panel in order to decompose the mixed X-ray image onto its constituent (imagined) X-ray images (see Fig. 4).</p><p>Results obtained for details from the Adam and Eve panels of the Ghent Altarpiece demonstrate the efficacy of our proposed approaches [1,2] in relation to previous ones [3,4]. See Figs. 5a and 5b.</p><center><figure class=\"figure\"><img src=\"graphics/ucl_01.jpg\" class=\"figure-img img-fluid rounded\" style=\"\" alt=\"The Ghent Altarpiece open\"><figcaption class=\"figure-caption\">Figure 1: The Ghent Altarpiece open. The bottom left panel of the open left wing has been missing since its theft in 1934. Images in this figure, used with permission of copyright holder, Saint-Bavo’s Cathedral, <a href=\"http://www.lukasweb.be\">www.lukasweb.be</a> – Art in Flanders; photo Hugo Maertens.<\/figcaption><\/figure><\/center><center><figure class=\"figure\"><img src=\"graphics/ucl_02.jpg\" class=\"figure-img img-fluid rounded\" style=\"\" alt=\"The Ghent Altarpiece closed\"><figcaption class=\"figure-caption\">Figure 2: The Ghent Altarpiece closed. Images in this figure, used with permission of copyright holder, Saint-Bavo’s Cathedral, <a href=\"http://www.lukasweb.be\">www.lukasweb.be</a> – Art in Flanders; photo Dominique Provost.<\/figcaption><\/figure><\/center><center><figure class=\"figure\"><img src=\"graphics/ucl_03.jpg\" class=\"figure-img img-fluid rounded\" style=\"\" alt=\"Two double-sided panels from the Ghent Altarpiece closed\"><figcaption class=\"figure-caption\">Figure 3: Two double-sided panels from the Ghent Altarpiece closed. Images in this figure, used with permission of copyright holder, Saint-Bavo’s Cathedral, <a href=\"http://www.lukasweb.be\">www.lukasweb.be</a> – Art in Flanders; photo Dominique Provost.<\/figcaption><\/figure><\/center><center><figure class=\"figure\"><img src=\"graphics/ucl_04.jpg\" class=\"figure-img img-fluid rounded\" style=\"\" alt=\"Process Digram\"><figcaption class=\"figure-caption\">Figure 4: A diagram of our proposed self-supervised neural network based X-ray image separation approach.<\/figcaption><\/figure><\/center><center><figure class=\"figure\"><img src=\"graphics/ucl_05.jpg\" class=\"figure-img img-fluid rounded\" style=\"\" alt=\"X-ray separation examples\"><figcaption class=\"figure-caption\">Figure 5: <b>a)</b> X-ray separation performed by the new neural networks based algorithm (left – mixed X-ray; center – visible images of each side; right – the reconstructed X-ray images). Images in this figure, used with permission of copyright holder, Saint-Bavo’s Cathedral, <a href=\"http://www.lukasweb.be\">www.lukasweb.be</a> – Art in Flanders; photos: Hugo Maertens (interior view; Adam), Dominique Provost (exterior view), KIK-IRPA (X-ray). <b>b)</b> X-ray separation performed by the new neural networks based algorithm (left – mixed X-ray; center – visible images of each side; right – the reconstructed X-ray images). Images in this figure, used with permission of copyright.<\/figcaption><\/figure><\/center><h2>Other Use-Cases </h2><p>Our team anticipates our proposed self-supervised deep learning based approaches can be adapted to tackle other related image separation challenges. These include the decomposition of a variety of mixed image modalities that contain various features present within a painting such as underdrawing and other pentimenti, or concealed designs.</p><h2>Representative Publications</h2><p>[1] Z. Sabetsarvestani, B. Sober, C. Higgitt, I. Daubechies, and M. R. D. Rodrigues. Artificial intelligence for art investigation: Meeting the challenge of separating x-ray images of the Ghent Altarpiece. Science Advances, 2019.</p><p>[2] W. Pu, B. Sober, N. Daly, C. Higgitt, I. Daubechies, M. R. D. Rodrigues. A connected auto-encoders based approach for image separation with side information: with applications to art investigation. IEEE International Conference on Acoustics, Speech and Signal Processing, 2020.</p><p>[3] Z. Sabetsarvestani, F. Renna, F. Kiraly and M. R. D. Rodrigues. Source Separation with Side Information Based on Gaussian Mixture Models With Application in Art Investigation. IEEE Transactions on Signal Processing, 2020.</p><p>[4] N. Deligiannis, J. F. C. Mota, B. Cornelis, M. R. D. Rodrigues, and I. Daubechies. Multi-Modal Dictionary Learning for Image Separation With Application In Art Investigation. IEEE Transactions on Image Processing, 2016.</p><h2>Representative Media Coverage</h2><p><a href=\"https://www.telegraph.co.uk/science/2019/08/30/hidden-works-goya-van-gogh-van-eyck-could-discovered-using-artifical/\">Hidden works of Goya, Van Gogh and Van Eyck could be discovered using artifical intelligence</a> - The Telegraph</p><p><a href=\"https://www.forbes.com/sites/simonchandler/2019/09/06/forget-the-future-ai-will-take-us-back-to-the-past/#1cc67ddd2d13\">Forget The Future, AI Will Take Us Back To The Past </a> - Forbes</p><div class=\"alert alert-success\" role=\"alert\">\r\n\t<b>Research Team: </b> <i>University College London</i> - Wei Pu, Miguel Rodrigues, Zahra Sabetsarvestani, <i>Duke University</i> - Ingrid Daubechies, Barak Sober, <i>National Gallery, London</i> - Nathan Daly, Catherine Higgitt.</div>",
	"content right": ""
	},
"publications": {
    "class": "list",
	"title": "ARTICT | Publications",
	"content": "<h2>Publications</h2><p>[1] S. Yan, J. Huang, N. Daly, C. Higgitt and P. L. Dragotti, <a href='https://ieeexplore.ieee.org/document/9054460'>Revealing Hidden Drawings in Leonardo’s ‘the Virgin of the Rocks’ from Macro X-Ray Fluorescence Scanning Data through Element Line Localisation</a>, IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), May 2020.</p><p>[2] W. Pu, B. Sober, N. Daly, C. Higgitt, I. Daubechies, M. R. D. Rodrigues. <a href='https://ieeexplore.ieee.org/document/9054651'>A connected auto-encoders based approach for image separation with side information: with applications to art investigation</a>. IEEE International Conference on Acoustics, Speech and Signal Processing, 2020.</p><p>[3] Z. Sabetsarvestani, F. Renna, F. Kiraly and M. R. D. Rodrigues. <a href='https://ieeexplore.ieee.org/document/8950399'>Source Separation with Side Information Based on Gaussian Mixture Models With Application in Art Investigation</a>. IEEE Transactions on Signal Processing, 2020.</p><p>[4] Z. Sabetsarvestani, B. Sober, C. Higgitt, I. Daubechies, and M. R. D. Rodrigues. <a href='https://advances.sciencemag.org/content/5/8/eaaw7416'>Artificial intelligence for art investigation: Meeting the challenge of separating x-ray images of the Ghent Altarpiece</a>. Science Advances, 2019.</p><p>[5] N. Deligiannis, J. F. C. Mota, B. Cornelis, M. R. D. Rodrigues, and I. Daubechies. <a href='https://ieeexplore.ieee.org/document/7725950'>Multi-Modal Dictionary Learning for Image Separation With Application In Art Investigation</a>. IEEE Transactions on Image Processing, 2016.</p>",
	"content right": ""		
	},
"data and tools": {
	"title": "ARTICT | Art Through the ICT Lens: Big Data Processing Tools to Support the Technical Study, Preservation and Conservation of Old Master Paintings",
	"content": "<h2>Data and tools</h2><p>This page will be used to share datasets and tools developed within the project. Links to other useful resources and outputs will also be provided.</p>",
	"content right": ""
	},
"events": {
	"title": "ARTICT - Events",
	"content": "<b>A number of events are planned as part of the ARTICT project. Please see below for links</b>",
	"content right": ""
	},
  "Computational approaches for technical imaging": {
		"parent": "events",
		"title": "Conference: Computational approaches for technical imaging in cultural heritage (7th IP4AI meeting)",
		"content": "<p><b>In light of the current COVID-19 situation the decision has been made to postpone this conference to April 2021 and the revised dates are detailed below</b><br/><b>8-9 April 2021</b><br/><b>The National Gallery, London, UK</b></p><br/><p>With the increasing use of a range of advanced technical imaging and spectroscopic imaging in the study and preservation of artworks and other cultural heritage artefacts, there is growing interest in and need for computational approaches to fully realise the potential in the data acquired and be able to address research questions in a variety of disciplines. This is a rapidly growing field of research that is only possible through cross-disciplinary collaboration.</p><p>The aim of this conference is to provide a forum to bring together a multi-disciplinary group of researchers including:</p><ul><li>scientists and conservators working with various forms of technical imaging or spectroscopic imaging on paintings and other cultural heritage artefacts in museums, galleries and universities</li><li>researchers working in computer science, computational image processing, machine learning, mathematics, and statistics</li><li>art historians, archaeologists and curators with an interest in the possibilities of technical imaging and/or those working in the digital humanities</li></ul><p>to share their research and find fertile areas of collaboration and common inquiry.</p><p>The conference is being held in London and at the National Gallery in the hope of encouraging an international attendance from both academic researchers and professionals working in cultural heritage organisations.</p><p>The conference is being organised as part of the EPSRC-funded <a href=\"./\">ARTICT | Art Through the ICT Lens: Big Data Processing Tools to Support the Technical Study, Preservation and Conservation of Old Master Paintings</a> project (a collaboration between the National Gallery, University College London and Imperial College London) and builds on the success of the <a href=\"https://www.ip4ai.ugent.be/\">Image processing for art investigation (IP4AI)</a> workshops, <a href=\"https://services.math.duke.edu/~ingrid/publications/paper_Bridges.pdf\">first established in 2007</a>. The aim of IP4AI is to support art scholarship with new computational tools that enable new findings.</p>",
	"content right": "<img style=\"position:relative;width:100%;\" src=\"graphics/ARTICT_conf_NG1473_v6.jpg\"/>"
		},
	"call for papers": {
		"parent": "Computational approaches for technical imaging",
		"title": "Call for papers",
		"content": "<p>We invite papers featuring both cutting-edge research based on applying computational approaches for technical imaging in cultural heritage and more preliminary research highlighting open problems and challenges in this rapidly evolving field. Topics for contributions might include:</p><ul><li>Advances in the application of technical imaging and spectroscopic imaging techniques (including MA-XRF, reflectance imaging spectroscopy, ATR-FTIR imaging, SEM-EDX, OCT imaging etc) in cultural heritage​</li><li>Multi-modal image and signal processing and combined use of spectroscopic imaging techniques​</li><li>Data deconvolution and image separation​</li><li>Registration, mosaicking and fusion of images and datacubes​</li><li>Approaches to data visualisation​</li><li>Image recognition​</li><li>Statistical and multivariate approaches to data analysis, interpretation and visualisation​</li><li>Machine learning, deep learning and AI approaches to data analysis, interpretation and visualisation</li><li>Novel algorithms, computational tools and software for cultural heritage applications</li><li>Case studies in conservation, art and archaeology (particularly those employing multiple analytical methods or novel computational approaches)​</li></ul><p>Please submit an abstract of up to 500 words (approx. 1 page). Abstracts should include a clear title, full list of authors and their affiliations and a brief summary of the work, with a few key references if needed. Please indicate if an oral or poster presentation would be preferred.​</p><p>Please send the abstracts by e-mail to <a href=\"mailto:artict@ng-london.org.uk?Subject=Abstract\" target=\"_top\">artict@ng-london.org.uk</a>​</p><p>Deadline: 30 September 2020​ [for those who have already submitted an abstract these will continue to be considered or updated versions can be submitted to the new deadline]</p><p>All accepted contributions will be incorporated into a proceedings",
	"content right": ""
		},
	"key dates": {
		"parent": "Computational approaches for technical imaging",
		"title": "Key dates",
		"content": "<p>In light of the current COVID-19 situation the decision has been made to postpone this conference until April 2021 and the revised schedule is detailed below</p><ul><li>Abstracts due: 30 September 2020​​</li><li>Acceptance notification: end October 2020​​</li><li>Registration: more details to follow​​</li><li>Conference: 8-9 April 2021​</li></ul>",
	"content right": ""
		},
	"programme": {
		"parent": "Computational approaches for technical imaging",
		"title": "Programme",
		"content": "<p>The conference programme is still being developed but the two-day event will include a mix of invited speakers and presentations and posters selected based on an open call for papers. It is also hoped to include some demonstrations of software or algorithms that have been developed for use in this area</p>",
	"content right": ""
		},
	"registration": {
		"parent": "Computational approaches for technical imaging",
		"title": "Registration",
		"content": "<p>The registration is free of charge but required to provide access to the workshop location</p><p>More details to follow</p>",
	"content right": ""
		},
	"committees": {
		"parent": "Computational approaches for technical imaging",
		"title": "Organizing and Scientific committees",
		"content": "<p><b>Organizing committee:</b></p><p><ul><li>Catherine Higgitt, Nathan Daly, Ann Stephenson-Wright and Tess Raven: National Gallery</li><li>Miguel Rodrigues, Cerys Jones, Wei Pu and Chao Zhou: University College London</li><li>Pier Luigi Dragotti, Junjie Huang, Su Yan and Maria Villafane: Imperial College London</li><li>Ingrid Daubechies, Barak Sober and Ashley Kwon: Duke University</li></ul></p><p>  </p><p>  </p><p>  </p><p>  </p><p><b>Scientific committee:</b></p><p>More details coming soon</p>",
	"content right": "<img style=\"position:relative;width:100%;\" src=\"graphics/logos.png\"/>"
		},
	"hotels and travel": {
		"parent": "Computational approaches for technical imaging",
		"title": "Hotel and travel information",
		"content": "<p>Further information to follow</p>",
	"content right": ""
		},
	"contact": {
		"parent": "Computational approaches for technical imaging",
		"title": "Venue and contact information",
		"content": "<p>For all enquiries, please use the conference email address: <a href=\"mailto:artict@ng-london.org.uk?Subject=Abstract\" target=\"_top\">artict@ng-london.org.uk</a>​​</p><p>The conference will be held in the <a href=\"https://www.nationalgallery.org.uk/visiting/floorplans/sainsbury-wing/sainsbury-wing-theatre/\">Sainsbury Wing Lecture Theatre</a> and <a href=\"https://www.nationalgallery.org.uk/visiting/floorplans/sainsbury-wing/sainsbury-wing-conference-rooms/\">Conference rooms</a> at the <a href=\"https://www.nationalgallery.org.uk/visiting/plan-your-visit/\">National Gallery, London</a></p><p>The National Gallery​</p><p>Trafalgar Square</p><p>London​</p><p>WC2N 5DN​</p>",
	"content right": ""
		}
}
